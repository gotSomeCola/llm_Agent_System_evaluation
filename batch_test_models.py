#!/usr/bin/env python3
"""
æ‰¹é‡æµ‹è¯•è„šæœ¬ï¼šä¾æ¬¡è¿è¡Œå¤šä¸ªæ¨¡å‹çš„è¯„ä¼°
å¯åŠ¨åå¯ä»¥å»ç¡è§‰ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰æµ‹è¯•
"""
import subprocess
import json
import time
import os
from datetime import datetime

# ========== é…ç½®åŒºåŸŸ ==========
# è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
MODELS_TO_TEST = [

    "gemma3:12b",
    "llama3.3:70b",          # Meta Llama 3.3 - 70B å‚æ•°ï¼ˆå¯é€‰ï¼‰
    "llama3.1:70b",
    "llama3:8b",
    "llama3.1:8b",
    "gpt-oss:20b",
    "gpt-oss:120b",
    "hf.co/unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF:latest",
]

# è¯„ä¼°å‚æ•°
EVAL_CONFIG = {
    "min_count": 0,
    "max_count": 1000,     # æµ‹è¯• 1000 ä¸ªä»»åŠ¡ â† æ”¹è¿™é‡Œ
    "workers": 3,           # 4 ä¸ªçº¿ç¨‹ â† è¿™ä¸ªå·²ç»å¯¹äº†
    "k": 1,                 # pass@1 è¯„ä¼° â† æ”¹è¿™é‡Œ
    "use_at_k": False       # ä½¿ç”¨ pass@1 è„šæœ¬ï¼ˆæ”¹ä¸º Falseï¼‰â† æ”¹è¿™é‡Œ
}

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "./results"

# ========== ä¸»ç¨‹åº ==========

def ensure_output_dir():
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
    os.makedirs(OUTPUT_DIR, exist_ok=True)

def generate_output_filename(model_name, timestamp):
    """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å"""
    # å°†æ¨¡å‹åä¸­çš„ç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    safe_model_name = model_name.replace(":", "_").replace("-", "_")
    return os.path.join(OUTPUT_DIR, f"results_{safe_model_name}_{timestamp}.jsonl")

def run_evaluation(model_name, output_file, config):
    """è¿è¡Œå•ä¸ªæ¨¡å‹çš„è¯„ä¼°"""
    print(f"\n{'='*70}")
    print(f"ğŸš€ å¯åŠ¨è¯„ä¼°: {model_name}")
    print(f"{'='*70}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"é…ç½®: {config}")
    
    # é€‰æ‹©è„šæœ¬
    script = "run_baseline_at_k.py" if config["use_at_k"] else "run_baseline.py"
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        "python", script,
        "--model_name", model_name,
        "--output_file", output_file,
        "--min_count", str(config["min_count"]),
        "--max_count", str(config["max_count"]),
        "--workers", str(config["workers"]),
    ]
    
    # å¦‚æœä½¿ç”¨ pass@kï¼Œæ·»åŠ  k å‚æ•°
    if config["use_at_k"]:
        cmd.extend(["--k", str(config["k"])])
    
    print(f"å‘½ä»¤: {' '.join(cmd)}\n")
    
    try:
        # è¿è¡Œè¯„ä¼°è„šæœ¬
        print("â³ è¿è¡Œè¯„ä¼°ä¸­...")
        result = subprocess.run(cmd, check=True)
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶æ˜¯å¦åˆ›å»º
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            print(f"\nâœ… è¯„ä¼°æˆåŠŸ!")
            print(f"JSONL è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(f"æ–‡ä»¶å¤§å°: {file_size / 1024:.2f} KB")
            
            # è‡ªåŠ¨ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
            print(f"\nâ³ ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Šä¸­...")
            generate_report(model_name, output_file)
            
            return True
        else:
            print(f"\nâš ï¸ è­¦å‘Š: è¾“å‡ºæ–‡ä»¶æœªåˆ›å»º")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ è¯„ä¼°å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"\nâŒ å‡ºé”™: {e}")
        return False

def generate_report(model_name, jsonl_file):
    """ä¸ºè¯„ä¼°ç»“æœç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š"""
    try:
        cmd = [
            "python", "generate_results_report.py",
            "--input", jsonl_file,
        ]
        
        print(f"å‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        
        print(f"âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
        print(f"è¾“å‡ºæ–‡ä»¶:")
        
        # æå–ç”Ÿæˆçš„æ–‡ä»¶å
        base_path = os.path.splitext(jsonl_file)[0]
        output_dir = os.path.dirname(jsonl_file)
        
        report_files = {
            "CSV": f"{base_path}.csv",
            "TXT æ€»ç»“": f"{base_path}_summary.txt",
            "åˆ†å¸ƒå›¾": f"{base_path}_distribution.png",
        }
        
        for file_type, file_path in report_files.items():
            if os.path.exists(file_path):
                print(f"  ğŸ“„ {file_type}: {file_path}")
        
        # æ˜¾ç¤º summary_all.csv çš„è·¯å¾„
        summary_all = os.path.join(output_dir, "summary_all.csv")
        if os.path.exists(summary_all):
            print(f"  ğŸ“Š ç´¯ç§¯å¯¹æ¯”: {summary_all}")
        
    except subprocess.CalledProcessError as e:
        print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}")

def main():
    """ä¸»ç¨‹åº"""
    print("\n" + "="*70)
    print("ğŸ“Š LLM ä»£ç ç”Ÿæˆè¯„ä¼° - æ‰¹é‡æµ‹è¯•æ¨¡å¼")
    print("="*70)
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•æ¨¡å‹æ•°: {len(MODELS_TO_TEST)}")
    print(f"æ¨¡å‹åˆ—è¡¨: {', '.join(MODELS_TO_TEST)}")
    print(f"è¯„ä¼°æ¨¡å¼: {'Pass@{} (å¤šæ¬¡å°è¯•)'.format(EVAL_CONFIG['k']) if EVAL_CONFIG['use_at_k'] else 'Pass@1 (å•æ¬¡å°è¯•)'}")
    print("="*70 + "\n")
    
    ensure_output_dir()
    
    # è®°å½•æ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    results_summary = {
        "start_time": datetime.now().isoformat(),
        "config": EVAL_CONFIG,
        "models": [],
        "end_time": None
    }
    
    # ä¾æ¬¡è¿è¡Œæ¯ä¸ªæ¨¡å‹
    for i, model_name in enumerate(MODELS_TO_TEST, 1):
        output_file = generate_output_filename(model_name, timestamp)
        
        print(f"\n[{i}/{len(MODELS_TO_TEST)}] å¤„ç†æ¨¡å‹: {model_name}")
        
        # è¿è¡Œè¯„ä¼°
        success = run_evaluation(model_name, output_file, EVAL_CONFIG)
        
        # è®°å½•ç»“æœ
        model_result = {
            "model": model_name,
            "output_file": output_file,
            "success": success,
            "timestamp": datetime.now().isoformat()
        }
        results_summary["models"].append(model_result)
        
        # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ¨¡å‹ï¼Œç­‰å¾…ä¸€ä¸‹
        if i < len(MODELS_TO_TEST):
            print(f"\nâ³ ç­‰å¾… 10 ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæ¨¡å‹...")
            time.sleep(10)
    
    # å®Œæˆ
    results_summary["end_time"] = datetime.now().isoformat()
    
    # ä¿å­˜æ€»ç»“
    summary_file = os.path.join(OUTPUT_DIR, f"batch_summary_{timestamp}.json")
    with open(summary_file, "w") as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æœ€ç»ˆæ€»ç»“
    print(f"\n\n" + "="*70)
    print("ğŸ“‹ æ‰¹é‡æµ‹è¯•å®Œæˆ!")
    print("="*70)
    print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ€»ç»“æ–‡ä»¶: {summary_file}\n")
    
    for i, model_result in enumerate(results_summary["models"], 1):
        status = "âœ… æˆåŠŸ" if model_result["success"] else "âŒ å¤±è´¥"
        print(f"{i}. {model_result['model']}: {status}")
        print(f"   åŸå§‹æ•°æ®: {model_result['output_file']}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶
        base_path = os.path.splitext(model_result['output_file'])[0]
        report_files = {
            "CSV": f"{base_path}.csv",
            "TXT": f"{base_path}_summary.txt",
            "å›¾è¡¨": f"{base_path}_distribution.png",
        }
        
        print(f"   æ ¼å¼åŒ–æŠ¥å‘Š:")
        for file_type, file_path in report_files.items():
            if os.path.exists(file_path):
                print(f"      ğŸ“„ {file_type}: {file_path}")
        print()
    
    # æ˜¾ç¤ºç´¯ç§¯å¯¹æ¯”æ–‡ä»¶
    summary_all_csv = os.path.join(OUTPUT_DIR, "summary_all.csv")
    if os.path.exists(summary_all_csv):
        print(f"ğŸ“Š ç´¯ç§¯å¯¹æ¯”æ–‡ä»¶: {summary_all_csv}")
        print(f"   ï¼ˆåŒ…å«æ‰€æœ‰æ¨¡å‹è¿è¡Œçš„æ±‡æ€»æ•°æ®ï¼Œç”¨äºå¯¹æ¯”åˆ†æï¼‰\n")
    
    print("="*70 + "\n")

if __name__ == "__main__":
    main()
